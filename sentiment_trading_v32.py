"""
üöÄ SENTIMENT –¢–û–†–ì–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê V3.2
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
import gymnasium as gym
from gymnasium import spaces
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Any
import re
import requests
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')


class SentimentConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
    
    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    SOCIAL_MEDIA_WEIGHT = 0.3      # –í–µ—Å —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    ON_CHAIN_WEIGHT = 0.2          # –í–µ—Å on-chain –º–µ—Ç—Ä–∏–∫
    MACRO_WEIGHT = 0.1             # –í–µ—Å –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    TECHNICAL_WEIGHT = 0.4         # –í–µ—Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
    SENTIMENT_WINDOW = 24          # –û–∫–Ω–æ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
    SENTIMENT_THRESHOLD = 0.1      # –ü–æ—Ä–æ–≥ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
    NEWS_IMPACT_DECAY = 0.9        # –ó–∞—Ç—É—Ö–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π
    
    # –¢–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    WINDOW_SIZE = 48
    INITIAL_BALANCE = 10000
    RISK_PER_TRADE = 0.025
    SENTIMENT_MULTIPLIER = 1.5     # –£—Å–∏–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –ø—Ä–∏ —Å–∏–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è—Ö
    
    # –û–±—É—á–µ–Ω–∏–µ
    TOTAL_TIMESTEPS = 10000
    LEARNING_RATE = 3e-4


class SentimentAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        self.positive_words = [
            'bullish', 'moon', 'pump', 'buy', 'hold', 'diamond', 'hands',
            'rocket', 'green', 'profit', 'gains', 'up', 'rise', 'surge',
            'breakout', 'bull', 'strong', 'support', 'resistance', 'btfd'
        ]
        
        self.negative_words = [
            'bearish', 'dump', 'sell', 'crash', 'down', 'red', 'loss',
            'fear', 'panic', 'drop', 'fall', 'weak', 'breakdown', 'bear',
            'correction', 'dip', 'liquidation', 'fud', 'rekt', 'bag'
        ]
        
        self.crypto_keywords = [
            'bitcoin', 'btc', 'ethereum', 'eth', 'crypto', 'blockchain',
            'defi', 'nft', 'altcoin', 'hodl', 'satoshi', 'whale'
        ]
    
    def analyze_text_sentiment(self, text: str) -> float:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º)"""
        if not text:
            return 0.0
        
        text = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫—Ä–∏–ø—Ç–æ-—Ç–µ–º–∞—Ç–∏–∫–∏
        crypto_relevance = sum(1 for word in self.crypto_keywords if word in text)
        if crypto_relevance == 0:
            return 0.0  # –ù–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
        positive_count = sum(1 for word in self.positive_words if word in text)
        negative_count = sum(1 for word in self.negative_words if word in text)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        text_length = len(text.split())
        if text_length == 0:
            return 0.0
        
        sentiment_score = (positive_count - negative_count) / max(text_length, 1)
        
        # –£—Å–∏–ª–∏–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª –¥–ª—è –≤—ã—Å–æ–∫–æ–π –∫—Ä–∏–ø—Ç–æ-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        sentiment_score *= min(crypto_relevance / 3, 1.0)
        
        return np.clip(sentiment_score, -1.0, 1.0)
    
    def generate_social_sentiment_data(self, n_points: int) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        print("üì± –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π...")
        
        np.random.seed(42)
        timestamps = pd.date_range(start='2023-01-01', periods=n_points, freq='1H')
        
        # –ë–∞–∑–æ–≤–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å —Ç—Ä–µ–Ω–¥–∞–º–∏
        base_sentiment = np.random.normal(0, 0.3, n_points)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏—è (–Ω–æ–≤–æ—Å—Ç–∏, –æ–±—ä—è–≤–ª–µ–Ω–∏—è)
        events = np.random.choice([0, 1], size=n_points, p=[0.95, 0.05])
        event_impact = np.random.normal(0, 0.8, n_points) * events
        
        # –ó–∞—Ç—É—Ö–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è —Å–æ–±—ã—Ç–∏–π
        for i in range(1, len(event_impact)):
            if events[i-1] == 1:
                event_impact[i] += event_impact[i-1] * SentimentConfig.NEWS_IMPACT_DECAY
        
        # –û–±—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        total_sentiment = base_sentiment + event_impact
        total_sentiment = np.clip(total_sentiment, -1, 1)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        df = pd.DataFrame({
            'timestamp': timestamps,
            'twitter_sentiment': total_sentiment + np.random.normal(0, 0.1, n_points),
            'reddit_sentiment': total_sentiment + np.random.normal(0, 0.15, n_points),
            'news_sentiment': total_sentiment + np.random.normal(0, 0.2, n_points),
            'social_volume': np.abs(total_sentiment) * 1000 + np.random.exponential(500, n_points),
            'mentions_count': np.abs(total_sentiment) * 100 + np.random.poisson(50, n_points),
            'influencer_sentiment': total_sentiment * 1.2 + np.random.normal(0, 0.2, n_points)
        })
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        for col in ['twitter_sentiment', 'reddit_sentiment', 'news_sentiment', 'influencer_sentiment']:
            df[col] = np.clip(df[col], -1, 1)
        
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        return df


class OnChainAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä on-chain –º–µ—Ç—Ä–∏–∫ –±–ª–æ–∫—á–µ–π–Ω–∞"""
    
    def generate_onchain_data(self, n_points: int) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö on-chain –¥–∞–Ω–Ω—ã—Ö"""
        print("‚õìÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è on-chain –¥–∞–Ω–Ω—ã—Ö...")
        
        np.random.seed(43)
        timestamps = pd.date_range(start='2023-01-01', periods=n_points, freq='1H')
        
        # –ë–∞–∑–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã
        price_trend = np.linspace(45000, 65000, n_points) + np.random.normal(0, 2000, n_points)
        
        # On-chain –º–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å —Ü–µ–Ω–æ–π
        df = pd.DataFrame({
            'timestamp': timestamps,
            'active_addresses': 800000 + price_trend / 100 + np.random.normal(0, 50000, n_points),
            'transaction_count': 250000 + price_trend / 200 + np.random.normal(0, 30000, n_points),
            'hash_rate': 200e18 + price_trend * 1e15 + np.random.normal(0, 10e18, n_points),
            'difficulty': 25e12 + price_trend * 1e9 + np.random.normal(0, 1e12, n_points),
            'exchange_inflow': np.random.exponential(1000, n_points),
            'exchange_outflow': np.random.exponential(1200, n_points),
            'whale_transactions': np.random.poisson(50, n_points),
            'new_addresses': 350000 + price_trend / 300 + np.random.normal(0, 20000, n_points)
        })
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        df['net_exchange_flow'] = df['exchange_inflow'] - df['exchange_outflow']
        df['address_growth_rate'] = df['new_addresses'].pct_change().rolling(24).mean()
        df['network_value'] = df['active_addresses'] * price_trend / 1000000
        
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π on-chain –¥–∞–Ω–Ω—ã—Ö")
        return df


class MacroEconomicAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def generate_macro_data(self, n_points: int) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üåç –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        np.random.seed(44)
        timestamps = pd.date_range(start='2023-01-01', periods=n_points, freq='1H')
        
        # –ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df = pd.DataFrame({
            'timestamp': timestamps,
            'dxy_index': 103 + np.cumsum(np.random.normal(0, 0.1, n_points)),  # Dollar index
            'vix_index': 20 + np.abs(np.cumsum(np.random.normal(0, 0.5, n_points))),  # Volatility
            'gold_price': 1900 + np.cumsum(np.random.normal(0, 5, n_points)),
            'sp500_index': 4000 + np.cumsum(np.random.normal(0, 10, n_points)),
            'fed_rate': 5.25 + np.cumsum(np.random.normal(0, 0.01, n_points)) / 100,
            'inflation_rate': 3.2 + np.cumsum(np.random.normal(0, 0.05, n_points)) / 100,
            'unemployment_rate': 3.7 + np.cumsum(np.random.normal(0, 0.02, n_points)) / 100
        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
        df['vix_index'] = np.clip(df['vix_index'], 10, 80)
        df['fed_rate'] = np.clip(df['fed_rate'], 0, 10)
        df['inflation_rate'] = np.clip(df['inflation_rate'], -2, 15)
        df['unemployment_rate'] = np.clip(df['unemployment_rate'], 2, 15)
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        df['risk_appetite'] = (100 - df['vix_index']) / 100  # –ê–ø–ø–µ—Ç–∏—Ç –∫ —Ä–∏—Å–∫—É
        df['dollar_strength'] = (df['dxy_index'] - 100) / 10
        df['macro_sentiment'] = (df['risk_appetite'] - df['dollar_strength']) / 2
        
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        return df


class SentimentFeatureExtractor(BaseFeaturesExtractor):
    """Feature Extractor —Å —É—á–µ—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, observation_space: gym.Space, features_dim: int = 256):
        super().__init__(observation_space, features_dim)
        
        if observation_space.shape is not None:
            self.seq_len = observation_space.shape[0]
            self.input_features = observation_space.shape[1]
        else:
            self.seq_len = SentimentConfig.WINDOW_SIZE
            self.input_features = 50
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        self.feature_net = nn.Sequential(
            nn.Linear(self.input_features, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # –ü—Ä–æ—Å—Ç–æ–π LSTM –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self.lstm = nn.LSTM(
            input_size=self.input_features,
            hidden_size=128,
            num_layers=1,
            batch_first=True,
            dropout=0.0
        )
        
        # –û–±—ä–µ–¥–∏–Ω—è—é—â–∞—è —Å–µ—Ç—å
        self.fusion_net = nn.Sequential(
            nn.Linear(128 + 64, features_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(features_dim, features_dim)
        )
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        batch_size, seq_len, features = observations.shape
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        last_obs = observations[:, -1, :]
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        feature_out = self.feature_net(last_obs)
        
        # LSTM –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        lstm_out, _ = self.lstm(observations)
        lstm_features = lstm_out[:, -1, :]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π output
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        combined_features = torch.cat([lstm_features, feature_out], dim=1)
        output = self.fusion_net(combined_features)
        
        return output


def combine_all_data_sources(price_data: pd.DataFrame, 
                           sentiment_data: pd.DataFrame,
                           onchain_data: pd.DataFrame, 
                           macro_data: pd.DataFrame) -> pd.DataFrame:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    print("üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    combined = price_data.copy()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
    sentiment_features = sentiment_data.drop(['timestamp'], axis=1)
    for col in sentiment_features.columns:
        combined[f'sentiment_{col}'] = sentiment_features[col].values
    
    # –î–æ–±–∞–≤–ª—è–µ–º on-chain –¥–∞–Ω–Ω—ã–µ
    onchain_features = onchain_data.drop(['timestamp'], axis=1)
    for col in onchain_features.columns:
        combined[f'onchain_{col}'] = onchain_features[col].values
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    macro_features = macro_data.drop(['timestamp'], axis=1)
    for col in macro_features.columns:
        combined[f'macro_{col}'] = macro_features[col].values
    
    # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    combined['overall_sentiment'] = (
        combined['sentiment_twitter_sentiment'] * 0.3 +
        combined['sentiment_reddit_sentiment'] * 0.3 +
        combined['sentiment_news_sentiment'] * 0.2 +
        combined['sentiment_influencer_sentiment'] * 0.2
    )
    
    combined['network_health'] = (
        combined['onchain_active_addresses'] / combined['onchain_active_addresses'].mean() +
        combined['onchain_transaction_count'] / combined['onchain_transaction_count'].mean()
    ) / 2
    
    combined['macro_risk'] = (
        combined['macro_vix_index'] / 50 +  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º VIX
        (1 - combined['macro_risk_appetite'])
    ) / 2
    
    # –£–¥–∞–ª—è–µ–º timestamp
    if 'timestamp' in combined.columns:
        combined = combined.drop(['timestamp'], axis=1)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    combined = combined.fillna(method='ffill').fillna(method='bfill')
    combined = combined.replace([np.inf, -np.inf], 0)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
    print("üìä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    from sklearn.preprocessing import StandardScaler
    
    # –û—Ç–¥–µ–ª—è–µ–º —Ü–µ–Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ
    price_cols = ['open', 'high', 'low', 'close', 'volume']
    other_cols = [col for col in combined.columns if col not in price_cols]
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º price –¥–∞–Ω–Ω—ã–µ –æ—Ç–¥–µ–ª—å–Ω–æ (log-returns –¥–ª—è —Ü–µ–Ω)
    for col in ['open', 'high', 'low', 'close']:
        if col in combined.columns:
            combined[f'{col}_normalized'] = np.log(combined[col] / combined[col].shift(1)).fillna(0)
            combined[f'{col}_normalized'] = np.clip(combined[f'{col}_normalized'], -0.1, 0.1)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º volume
    if 'volume' in combined.columns:
        combined['volume_normalized'] = (combined['volume'] - combined['volume'].mean()) / combined['volume'].std()
        combined['volume_normalized'] = np.clip(combined['volume_normalized'], -3, 3)
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    if other_cols:
        scaler = StandardScaler()
        combined[other_cols] = scaler.fit_transform(combined[other_cols])
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        for col in other_cols:
            combined[col] = np.clip(combined[col], -5, 5)
    
    # –ó–∞–º–µ–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ü–µ–Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏
    cols_to_drop = []
    for col in price_cols:
        if col in combined.columns and f'{col}_normalized' in combined.columns:
            combined[col] = combined[f'{col}_normalized']
            cols_to_drop.append(f'{col}_normalized')
    
    combined = combined.drop(cols_to_drop, axis=1)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ Inf
    combined = combined.fillna(0)
    combined = combined.replace([np.inf, -np.inf], 0)
    
    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ {len(combined.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return combined


def generate_comprehensive_crypto_data(n_points: int = 8000) -> pd.DataFrame:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Ü–µ–Ω–æ–π"""
    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö —Ü–µ–Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    np.random.seed(40)
    timestamps = pd.date_range(start='2023-01-01', periods=n_points, freq='1H')
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π —Ü–µ–Ω—ã Bitcoin
    trend = np.linspace(45000, 62000, n_points)
    seasonal = 3000 * np.sin(2 * np.pi * np.arange(n_points) / 168)  # –ù–µ–¥–µ–ª—å–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
    volatility_events = np.random.normal(0, 1000, n_points)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä—É–ø–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è (–Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–±—ã—Ç–∏—è)
    major_events = np.random.choice([0, 1], size=n_points, p=[0.98, 0.02])
    event_impact = np.random.normal(0, 5000, n_points) * major_events
    
    close_price = trend + seasonal + volatility_events + event_impact
    close_price = np.maximum(close_price, 20000)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
    
    # OHLCV –¥–∞–Ω–Ω—ã–µ
    df = pd.DataFrame({
        'timestamp': timestamps,
        'open': close_price + np.random.normal(0, 100, n_points),
        'high': close_price * (1 + np.abs(np.random.normal(0, 0.008, n_points))),
        'low': close_price * (1 - np.abs(np.random.normal(0, 0.008, n_points))),
        'close': close_price,
        'volume': np.random.exponential(1500000, n_points)
    })
    
    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è high/low
    df['high'] = np.maximum(df['high'], df[['open', 'close']].max(axis=1))
    df['low'] = np.minimum(df['low'], df[['open', 'close']].min(axis=1))
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    df['returns'] = df['close'].pct_change()
    df['sma_20'] = df['close'].rolling(20).mean()
    df['ema_12'] = df['close'].ewm(span=12).mean()
    df['volatility'] = df['returns'].rolling(24).std()
    
    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π —Ü–µ–Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    return df


class SentimentTradingEnv(gym.Env):
    """–¢–æ—Ä–≥–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å –∞–Ω–∞–ª–∏–∑–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    
    def __init__(self, combined_df: pd.DataFrame):
        super().__init__()
        
        self.df = combined_df.reset_index(drop=True)
        self.window_size = SentimentConfig.WINDOW_SIZE
        
        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        self.action_space = spaces.Discrete(3)  # Hold, Buy, Sell
        
        n_features = len(combined_df.columns)
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf,
            shape=(self.window_size, n_features),
            dtype=np.float32
        )
        
        self._reset_state()
    
    def _reset_state(self):
        """–°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        self.current_step = self.window_size
        self.balance = SentimentConfig.INITIAL_BALANCE
        self.btc_amount = 0.0
        self.entry_price = 0.0
        
        self.total_trades = 0
        self.profitable_trades = 0
        self.portfolio_history = [float(SentimentConfig.INITIAL_BALANCE)]
        self.trades_history = []
        
        # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        self.sentiment_signals = []
        self.macro_signals = []
    
    def reset(self, seed=None, options=None):
        self._reset_state()
        return self._get_observation(), {}
    
    def _get_observation(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è"""
        start_idx = max(0, self.current_step - self.window_size)
        end_idx = self.current_step
        
        obs = self.df.iloc[start_idx:end_idx].values
        
        if len(obs) < self.window_size:
            padding = np.tile(obs[0], (self.window_size - len(obs), 1))
            obs = np.vstack([padding, obs])
        
        return obs.astype(np.float32)
    
    def _get_current_price(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã"""
        if self.current_step >= len(self.df):
            return self.df.iloc[-1]['close']
        return self.df.iloc[self.current_step]['close']
    
    def _get_sentiment_signal(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        if self.current_step >= len(self.df):
            return 0.0
        
        current_data = self.df.iloc[self.current_step]
        
        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        if 'overall_sentiment' in current_data.index:
            sentiment = current_data['overall_sentiment']
        else:
            sentiment = 0.0
        
        # –£—Å–∏–ª–µ–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        if abs(sentiment) > SentimentConfig.SENTIMENT_THRESHOLD:
            sentiment *= SentimentConfig.SENTIMENT_MULTIPLIER
        
        return np.clip(sentiment, -1, 1)
    
    def _execute_sentiment_aware_trade(self, action: int, current_price: float) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        sentiment_signal = self._get_sentiment_signal()
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        sentiment_multiplier = 1.0 + abs(sentiment_signal) * 0.5
        adjusted_risk = SentimentConfig.RISK_PER_TRADE * sentiment_multiplier
        adjusted_risk = min(adjusted_risk, 0.05)  # –ú–∞–∫—Å–∏–º—É–º 5%
        
        trade_result = {'executed': False, 'type': None, 'sentiment_signal': sentiment_signal}
        
        if action == 1 and self.balance > 100:  # Buy
            # –ü–æ–∫—É–ø–∞–µ–º –±–æ–ª—å—à–µ –ø—Ä–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏
            if sentiment_signal > 0:
                investment = self.balance * adjusted_risk
            else:
                investment = self.balance * SentimentConfig.RISK_PER_TRADE * 0.5  # –ú–µ–Ω—å—à–µ –ø—Ä–∏ –Ω–µ–≥–∞—Ç–∏–≤–µ
            
            amount = investment / current_price
            commission = investment * 0.001
            
            self.btc_amount += amount
            self.balance -= investment + commission
            self.entry_price = current_price
            
            trade_result.update({
                'executed': True, 'type': 'BUY',
                'amount': amount, 'price': current_price,
                'investment': investment,
                'sentiment_adjusted': True
            })
            
        elif action == 2 and self.btc_amount > 0:  # Sell
            revenue = self.btc_amount * current_price
            commission = revenue * 0.001
            
            profit = revenue - self.btc_amount * self.entry_price
            if profit > 0:
                self.profitable_trades += 1
            
            self.balance += revenue - commission
            self.btc_amount = 0.0
            self.entry_price = 0.0
            
            trade_result.update({
                'executed': True, 'type': 'SELL',
                'amount': self.btc_amount, 'price': current_price,
                'revenue': revenue, 'profit': profit
            })
        
        if trade_result['executed']:
            self.total_trades += 1
            self.trades_history.append(trade_result)
            self.sentiment_signals.append(sentiment_signal)
        
        return trade_result
    
    def _calculate_portfolio_value(self) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        current_price = self._get_current_price()
        return self.balance + self.btc_amount * current_price
    
    def _calculate_reward(self) -> float:
        """–†–∞—Å—á–µ—Ç –Ω–∞–≥—Ä–∞–¥—ã —Å —É—á–µ—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        current_portfolio = self._calculate_portfolio_value()
        prev_portfolio = self.portfolio_history[-1]
        
        # –ë–∞–∑–æ–≤–∞—è –Ω–∞–≥—Ä–∞–¥–∞
        portfolio_change = (current_portfolio - prev_portfolio) / prev_portfolio
        base_reward = portfolio_change * 100
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        sentiment_signal = self._get_sentiment_signal()
        if len(self.sentiment_signals) > 0:
            last_sentiment = self.sentiment_signals[-1]
            if abs(last_sentiment) > SentimentConfig.SENTIMENT_THRESHOLD:
                # –ë–æ–Ω—É—Å –∑–∞ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–∏–ª—å–Ω—ã–º —Å–∏–≥–Ω–∞–ª–∞–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
                sentiment_bonus = abs(last_sentiment) * 0.5
                if (last_sentiment > 0 and portfolio_change > 0) or (last_sentiment < 0 and portfolio_change > 0):
                    base_reward += sentiment_bonus
        
        return base_reward
    
    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict[str, Any]]:
        """–®–∞–≥ —Å–∏–º—É–ª—è—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        current_price = self._get_current_price()
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è
        trade_result = self._execute_sentiment_aware_trade(action, current_price)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.current_step += 1
        portfolio_value = self._calculate_portfolio_value()
        self.portfolio_history.append(portfolio_value)
        
        # –†–∞—Å—á–µ—Ç –Ω–∞–≥—Ä–∞–¥—ã
        reward = self._calculate_reward()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        done = (
            self.current_step >= len(self.df) - 1 or
            portfolio_value <= SentimentConfig.INITIAL_BALANCE * 0.1
        )
        
        info = {
            'portfolio_value': portfolio_value,
            'balance': self.balance,
            'btc_amount': self.btc_amount,
            'total_trades': self.total_trades,
            'sentiment_signal': trade_result.get('sentiment_signal', 0),
            'trade_result': trade_result
        }
        
        return self._get_observation(), reward, done, False, info


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π V3.2"""
    print("üöÄ –ó–ê–ü–£–°–ö SENTIMENT –¢–û–†–ì–û–í–û–ô –°–ò–°–¢–ï–ú–´ V3.2")
    print("=" * 60)
    
    # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –≠–¢–ê–ü 1: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–û–ú–ü–õ–ï–ö–°–ù–´–• –î–ê–ù–ù–´–•")
    print("-" * 40)
    
    n_points = 6000
    price_data = generate_comprehensive_crypto_data(n_points)
    
    sentiment_analyzer = SentimentAnalyzer()
    sentiment_data = sentiment_analyzer.generate_social_sentiment_data(n_points)
    
    onchain_analyzer = OnChainAnalyzer()
    onchain_data = onchain_analyzer.generate_onchain_data(n_points)
    
    macro_analyzer = MacroEconomicAnalyzer()
    macro_data = macro_analyzer.generate_macro_data(n_points)
    
    # 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print("\nüîÑ –≠–¢–ê–ü 2: –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –ò–°–¢–û–ß–ù–ò–ö–û–í –î–ê–ù–ù–´–•")
    print("-" * 40)
    combined_df = combine_all_data_sources(price_data, sentiment_data, onchain_data, macro_data)
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    print("\nüéÆ –≠–¢–ê–ü 3: –°–û–ó–î–ê–ù–ò–ï SENTIMENT –û–ö–†–£–ñ–ï–ù–ò–Ø")
    print("-" * 40)
    env = SentimentTradingEnv(combined_df)
    vec_env = DummyVecEnv([lambda: env])
    print(f"‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ —Å {len(combined_df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nüß† –≠–¢–ê–ü 4: –°–û–ó–î–ê–ù–ò–ï SENTIMENT –ú–û–î–ï–õ–ò")
    print("-" * 40)
    
    policy_kwargs = dict(
        features_extractor_class=SentimentFeatureExtractor,
        features_extractor_kwargs=dict(features_dim=256),
        net_arch=[256, 128],
        activation_fn=torch.nn.ReLU
    )
    
    model = PPO(
        'MlpPolicy',
        vec_env,
        learning_rate=SentimentConfig.LEARNING_RATE,
        n_steps=1024,
        batch_size=32,
        n_epochs=5,
        gamma=0.98,
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.01,
        vf_coef=0.5,
        max_grad_norm=0.5,
        policy_kwargs=policy_kwargs,
        verbose=1
    )
    
    print("‚úÖ Sentiment –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    
    # 5. –û–±—É—á–µ–Ω–∏–µ
    print("\nüéì –≠–¢–ê–ü 5: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("-" * 40)
    model.learn(total_timesteps=SentimentConfig.TOTAL_TIMESTEPS)
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # 6. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\nüß™ –≠–¢–ê–ü 6: –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï")
    print("-" * 40)
    
    obs, _ = env.reset()
    results = []
    sentiment_history = []
    
    for step in range(2000):
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, done, truncated, info = env.step(int(action))
        
        results.append({
            'step': step,
            'portfolio_value': info['portfolio_value'],
            'balance': info['balance'],
            'total_trades': info['total_trades'],
            'sentiment_signal': info['sentiment_signal'],
            'reward': reward
        })
        
        sentiment_history.append(info['sentiment_signal'])
        
        if done:
            break
    
    # 7. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüìä –≠–¢–ê–ü 7: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("-" * 40)
    
    final_value = results[-1]['portfolio_value']
    total_return = (final_value - SentimentConfig.INITIAL_BALANCE) / SentimentConfig.INITIAL_BALANCE * 100
    total_trades = results[-1]['total_trades']
    avg_sentiment = np.mean([abs(s) for s in sentiment_history])
    
    print("üìä –ê–ù–ê–õ–ò–ó SENTIMENT –¢–û–†–ì–û–í–û–ô –°–ò–°–¢–ï–ú–´ V3.2")
    print("=" * 55)
    print(f"üí∞ –ù–∞—á–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: {SentimentConfig.INITIAL_BALANCE:,.2f} USDT")
    print(f"üí∞ –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {final_value:,.2f} USDT")
    print(f"üìà –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return:+.2f}%")
    print(f"üîÑ –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total_trades}")
    print(f"üì± –°—Ä–µ–¥–Ω—è—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π: {avg_sentiment:.3f}")
    print(f"üîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö: –°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ + On-chain + –ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞")
    
    # 8. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    print("\nüéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï V3.2")
    print("=" * 50)
    print("üöÄ Sentiment —Ç–æ—Ä–≥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ V3.2 —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞!")
    print(f"üí° –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return:+.2f}%")
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö: 4 (—Ü–µ–Ω–∞ + –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è + on-chain + –º–∞–∫—Ä–æ)")
    print("\n‚ú® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ V3.2:")
    print("  ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π")
    print("  ‚Ä¢ On-chain –º–µ—Ç—Ä–∏–∫–∏ –±–ª–æ–∫—á–µ–π–Ω–∞")
    print("  ‚Ä¢ –ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
    print("  ‚Ä¢ Multi-modal –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏")
    print("  ‚Ä¢ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π")
    print("  ‚Ä¢ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    if total_return > 0:
        print("\nüü¢ –û–¶–ï–ù–ö–ê: –ü—Ä–∏–±—ã–ª—å–Ω–∞—è sentiment-driven —Å—Ç—Ä–∞—Ç–µ–≥–∏—è!")
    else:
        print("\nüî∂ –û–¶–ï–ù–ö–ê: –¢—Ä–µ–±—É–µ—Ç –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    
    print("\nüéâ –ê–ù–ê–õ–ò–ó V3.2 –ó–ê–í–ï–†–®–ï–ù!")


if __name__ == "__main__":
    main() 