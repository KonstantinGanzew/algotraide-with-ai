"""
üìä –ú–û–î–£–õ–¨ –ó–ê–ì–†–£–ó–ö–ò –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–•
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–æ 6+ –ª–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏
"""

import pandas as pd
import numpy as np
import requests
import time
from datetime import datetime, timedelta
import logging
from pathlib import Path
from typing import Optional, List, Dict, Tuple
import ccxt
import yfinance as yf

logger = logging.getLogger(__name__)


class HistoricalDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    def __init__(self, data_folder: str = "data"):
        self.data_folder = Path(data_folder)
        self.data_folder.mkdir(exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∏—Ä–∂
        self.exchanges = {
            'binance': ccxt.binance(),
            'okx': ccxt.okx(),
            'bybit': ccxt.bybit()
        }
    
    def load_yahoo_finance_data(self, symbol: str = "BTC-USD", period: str = "6y", interval: str = "5m") -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Yahoo Finance
        
        Args:
            symbol: –°–∏–º–≤–æ–ª (BTC-USD, ETH-USD)
            period: –ü–µ—Ä–∏–æ–¥ (6y, 5y, 3y, 1y)
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª (1m, 5m, 15m, 1h, 1d)
        """
        try:
            logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö {symbol} —Å Yahoo Finance...")
            
            ticker = yf.Ticker(symbol)
            
            # Yahoo Finance –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤
            if interval in ['1m', '2m', '5m']:
                # –î–ª—è –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–∞–∫—Å–∏–º—É–º 7 –¥–Ω–µ–π
                end_date = datetime.now()
                start_date = end_date - timedelta(days=7)
                data = ticker.history(start=start_date, end=end_date, interval=interval)
            elif interval in ['15m', '30m', '1h']:
                # –î–ª—è —á–∞—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–∞–∫—Å–∏–º—É–º 60 –¥–Ω–µ–π
                end_date = datetime.now()
                start_date = end_date - timedelta(days=60)
                data = ticker.history(start=start_date, end=end_date, interval=interval)
            else:
                # –î–ª—è –¥–Ω–µ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ
                data = ticker.history(period=period, interval=interval)
            
            if data.empty:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
                return pd.DataFrame()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            df = pd.DataFrame()
            df['timestamp'] = data.index.astype(int) // 10**6  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            df['open'] = data['Open'].values
            df['high'] = data['High'].values
            df['low'] = data['Low'].values
            df['close'] = data['Close'].values
            df['volume'] = data['Volume'].values
            
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ Yahoo Finance")
            return df
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Yahoo Finance: {e}")
            return pd.DataFrame()
    
    def load_binance_historical(self, symbol: str = "BTCUSDT", interval: str = "5m", 
                               start_date: str = "2018-01-01", limit: int = 1000) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å Binance
        
        Args:
            symbol: –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª (1m, 5m, 15m, 1h, 1d)
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –∑–∞ –∑–∞–ø—Ä–æ—Å (–º–∞–∫—Å 1000)
        """
        try:
            logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö {symbol} —Å Binance...")
            
            exchange = self.exchanges['binance']
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç—ã –≤ timestamp
            start_ts = int(datetime.strptime(start_date, "%Y-%m-%d").timestamp() * 1000)
            current_ts = int(datetime.now().timestamp() * 1000)
            
            all_data = []
            
            while start_ts < current_ts:
                try:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–∞—Å—Ç—è–º–∏
                    ohlcv = exchange.fetch_ohlcv(
                        symbol, interval, since=start_ts, limit=limit
                    )
                    
                    if not ohlcv:
                        break
                    
                    all_data.extend(ohlcv)
                    start_ts = ohlcv[-1][0] + 1  # –°–ª–µ–¥—É—é—â–∏–π timestamp
                    
                    logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(ohlcv)} –∑–∞–ø–∏—Å–µ–π, –≤—Å–µ–≥–æ: {len(all_data)}")
                    time.sleep(0.1)  # –°–æ–±–ª—é–¥–∞–µ–º rate limits
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
                    break
            
            if not all_data:
                return pd.DataFrame()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame
            df = pd.DataFrame(all_data)
            df.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp')
            
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π —Å Binance")
            return df
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Binance: {e}")
            return pd.DataFrame()
    
    def load_multiple_timeframes(self, symbol: str = "BTCUSDT", 
                               timeframes: List[str] = ["5m", "15m", "1h", "4h", "1d"]) -> Dict[str, pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö"""
        
        logger.info(f"üìà –ó–∞–≥—Ä—É–∑–∫–∞ –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
        
        data = {}
        for tf in timeframes:
            try:
                df = self.load_binance_historical(symbol, tf, "2018-01-01")
                if not df.empty:
                    data[tf] = df
                    self.save_data(df, f"{symbol}_{tf}_6y.csv")
                    logger.info(f"‚úÖ {tf}: {len(df)} –∑–∞–ø–∏—Å–µ–π")
                else:
                    logger.warning(f"‚ö†Ô∏è {tf}: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            except Exception as e:
                logger.error(f"‚ùå {tf}: {e}")
        
        return data
    
    def combine_datasets(self, files: List[str]) -> pd.DataFrame:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        
        logger.info("üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
        
        combined_data = []
        for file in files:
            file_path = self.data_folder / file
            if file_path.exists():
                df = pd.read_csv(file_path)
                combined_data.append(df)
                logger.info(f"üìÅ {file}: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
        if not combined_data:
            return pd.DataFrame()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        result = pd.concat(combined_data, ignore_index=True)
        result = result.drop_duplicates(subset=['timestamp']).sort_values('timestamp')
        
        logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {len(result)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        return result
    
    def save_data(self, df: pd.DataFrame, filename: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV"""
        
        file_path = self.data_folder / filename
        df.to_csv(file_path, index=False)
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename} ({len(df)} –∑–∞–ø–∏—Å–µ–π)")
    
    def validate_data_quality(self, df: pd.DataFrame) -> Dict[str, any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        if df.empty:
            return {'status': 'empty'}
        
        quality = {
            'total_records': len(df),
            'date_range': {
                'start': pd.to_datetime(df['timestamp'].min(), unit='ms'),
                'end': pd.to_datetime(df['timestamp'].max(), unit='ms')
            },
            'missing_values': df.isnull().sum().to_dict(),
            'duplicates': df.duplicated(subset=['timestamp']).sum(),
            'price_anomalies': {
                'negative_prices': (df[['open', 'high', 'low', 'close']] < 0).sum().sum(),
                'zero_volume': (df['volume'] == 0).sum(),
                'ohlc_errors': ((df['high'] < df['low']) | 
                              (df['close'] > df['high']) | 
                              (df['close'] < df['low']) |
                              (df['open'] > df['high']) | 
                              (df['open'] < df['low'])).sum()
            }
        }
        
        return quality
    
    def create_extended_dataset(self) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ 6-–ª–µ—Ç–Ω–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        
        logger.info("üöÄ –°–û–ó–î–ê–ù–ò–ï –†–ê–°–®–ò–†–ï–ù–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê (6 –õ–ï–¢)")
        logger.info("=" * 50)
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        datasets = []
        
        # Binance –¥–∞–Ω–Ω—ã–µ (–æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫)
        try:
            binance_data = self.load_binance_historical("BTCUSDT", "5m", "2018-01-01")
            if not binance_data.empty:
                datasets.append(binance_data)
                logger.info(f"üìà Binance: {len(binance_data)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            logger.error(f"‚ùå Binance error: {e}")
        
        # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        existing_files = ["BTC_5_96w.csv", "BTC_5_2w.csv"]
        for file in existing_files:
            file_path = self.data_folder / file
            if file_path.exists():
                df = pd.read_csv(file_path)
                datasets.append(df)
                logger.info(f"üìÅ {file}: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        if datasets:
            combined = pd.concat(datasets, ignore_index=True)
            combined = combined.drop_duplicates(subset=['timestamp']).sort_values('timestamp')
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            quality = self.validate_data_quality(combined)
            logger.info(f"üìä –ò–¢–û–ì–û: {quality['total_records']} –∑–∞–ø–∏—Å–µ–π")
            logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {quality['date_range']['start']} - {quality['date_range']['end']}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            self.save_data(combined, "BTC_5m_6years_extended.csv")
            
            return combined
        
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç")
        return pd.DataFrame()


# –£–¥–æ–±–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def download_6year_data():
    """–ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ 6-–ª–µ—Ç–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    loader = HistoricalDataLoader()
    return loader.create_extended_dataset()


def get_multi_timeframe_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö"""
    loader = HistoricalDataLoader()
    return loader.load_multiple_timeframes()


if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    loader = HistoricalDataLoader()
    extended_data = loader.create_extended_dataset()
    
    if not extended_data.empty:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(extended_data)} –∑–∞–ø–∏—Å–µ–π")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç") 