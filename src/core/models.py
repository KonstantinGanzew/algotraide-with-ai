"""
ML –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–ª–≥–æ—Ç—Ä–µ–π–¥–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã

–ü–†–û–ë–õ–ï–ú–´ –í –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò:
1. –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è LSTM (512 hidden, 3 layers) - –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
2. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
3. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã PPO

–ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
1. –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è LSTM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
2. –î–æ–±–∞–≤–ª–µ–Ω dropout –∏ batch normalization  
3. –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ PPO
4. –£–ª—É—á—à–µ–Ω–Ω—ã–π early stopping
"""

import torch
import torch.nn as nn
import numpy as np
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3 import PPO
import gymnasium as gym
from typing import Dict, Any, Optional
import logging

from .config import MLConfig, SystemConfig


class ImprovedLSTMFeatureExtractor(BaseFeaturesExtractor):
    """
    –£–õ–£–ß–®–ï–ù–ù–´–ô LSTM Feature Extractor —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    
    –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞:
    1. –£–º–µ–Ω—å—à–µ–Ω —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (256 -> 128)
    2. –î–æ–±–∞–≤–ª–µ–Ω dropout –∏ batch norm
    3. –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    4. –õ—É—á—à–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
    """
    
    def __init__(self, observation_space: gym.Space, features_dim: int = 128):
        super().__init__(observation_space, features_dim)
        
        logger = logging.getLogger(__name__)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–∞
        if observation_space.shape is not None:
            n_input_features = observation_space.shape[-1]
            sequence_length = observation_space.shape[0]
        else:
            # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
            n_input_features = 20
            sequence_length = 50
        
        logger.info(f"LSTM –º–æ–¥–µ–ª—å: –≤—Ö–æ–¥={n_input_features}, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å={sequence_length}, –≤—ã—Ö–æ–¥={features_dim}")
        
        # –£–ü–†–û–©–ï–ù–ù–ê–Ø LSTM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        self.lstm_hidden_size = MLConfig.LSTM_HIDDEN_SIZE  # 256 –≤–º–µ—Å—Ç–æ 512
        self.lstm_layers = MLConfig.LSTM_NUM_LAYERS        # 2 –≤–º–µ—Å—Ç–æ 3
        
        # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        self.input_norm = nn.BatchNorm1d(n_input_features)
        
        # LSTM —Å–ª–æ–∏ —Å dropout
        self.lstm = nn.LSTM(
            input_size=n_input_features,
            hidden_size=self.lstm_hidden_size,
            num_layers=self.lstm_layers,
            batch_first=True,
            dropout=MLConfig.LSTM_DROPOUT if self.lstm_layers > 1 else 0,
            bidirectional=False  # –£–±–∏—Ä–∞–µ–º bidirectional –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
        )
        
        # –°–ª–æ–∏ –ø–æ—Å–ª–µ LSTM
        self.feature_net = nn.Sequential(
            nn.Dropout(MLConfig.LSTM_DROPOUT),
            nn.Linear(self.lstm_hidden_size, features_dim),
            nn.ReLU(),
            nn.BatchNorm1d(features_dim),
            nn.Dropout(MLConfig.LSTM_DROPOUT * 0.5),
            nn.Linear(features_dim, features_dim),
            nn.ReLU()
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        self._init_weights()
    
    def _init_weights(self):
        """–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è LSTM"""
        for name, param in self.lstm.named_parameters():
            if 'weight_ih' in name:
                torch.nn.init.xavier_uniform_(param.data)
            elif 'weight_hh' in name:
                torch.nn.init.orthogonal_(param.data)
            elif 'bias' in name:
                param.data.fill_(0)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è linear —Å–ª–æ–µ–≤
        for layer in self.feature_net:
            if isinstance(layer, nn.Linear):
                torch.nn.init.xavier_uniform_(layer.weight)
                torch.nn.init.constant_(layer.bias, 0)
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        batch_size = observations.shape[0]
        seq_len = observations.shape[1]
        features = observations.shape[2]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–∞
        # Reshape –¥–ª—è batch norm: (batch * seq, features)
        obs_reshaped = observations.view(-1, features)
        obs_normalized = self.input_norm(obs_reshaped)
        obs_normalized = obs_normalized.view(batch_size, seq_len, features)
        
        # LSTM –æ–±—Ä–∞–±–æ—Ç–∫–∞
        lstm_out, (hidden, cell) = self.lstm(obs_normalized)
        
        # –ë–µ—Ä–µ–º –≤—ã—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —à–∞–≥–∞
        last_output = lstm_out[:, -1, :]  # (batch_size, hidden_size)
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏
        features = self.feature_net(last_output)
        
        return features


class SmartEarlyStoppingCallback(BaseCallback):
    """
    –£–õ–£–ß–®–ï–ù–ù–´–ô callback —Å —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
    
    –ò–∑–º–µ–Ω–µ–Ω–∏—è:
    1. –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    2. –õ—É—á—à–µ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    3. –ó–∞—â–∏—Ç–∞ –æ—Ç –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
    """
    
    def __init__(self, verbose: int = 1):
        super().__init__(verbose)
        
        # –°—á–µ—Ç—á–∏–∫–∏
        self.step_count = 0
        self.episode_count = 0
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.best_reward = float('-inf')
        self.episodes_without_improvement = 0
        self.episode_rewards_history = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config
        self.patience = MLConfig.EARLY_STOPPING_PATIENCE
        self.min_episodes = MLConfig.MIN_EPISODES_BEFORE_STOPPING
        self.improvement_threshold = MLConfig.IMPROVEMENT_THRESHOLD
        self.window_size = 20  # –û–∫–Ω–æ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        
        # –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
        self.progress_interval = 5000
        
        logger = logging.getLogger(__name__)
        logger.info(f"Early Stopping: —Ç–µ—Ä–ø–µ–Ω–∏–µ={self.patience}, –º–∏–Ω_—ç–ø–∏–∑–æ–¥–æ–≤={self.min_episodes}")
    
    def _on_step(self) -> bool:
        """Callback –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –æ–±—É—á–µ–Ω–∏—è"""
        self.step_count += 1
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —ç–ø–∏–∑–æ–¥—ã
        if len(self.locals.get('infos', [])) > 0:
            for info in self.locals['infos']:
                if 'episode' in info:
                    episode_reward = info['episode'].get('r', 0)
                    self.episode_count += 1
                    self.episode_rewards_history.append(episode_reward)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
                    if len(self.episode_rewards_history) >= self.window_size:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
                        recent_avg = np.mean(self.episode_rewards_history[-self.window_size:])
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–∏–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
                        if recent_avg > self.best_reward + self.improvement_threshold:
                            improvement = recent_avg - self.best_reward
                            self.best_reward = recent_avg
                            self.episodes_without_improvement = 0
                            
                            if self.verbose >= 1:
                                logger = logging.getLogger(__name__)
                                logger.info(f"üöÄ [–≠–ø–∏–∑–æ–¥ {self.episode_count}] –ù–æ–≤—ã–π —Ä–µ–∫–æ—Ä–¥: {recent_avg:.4f} (+{improvement:.4f})")
                        else:
                            self.episodes_without_improvement += 1
                            
                            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –æ—Ç—á–µ—Ç—ã
                            if self.episode_count % 10 == 0 and self.verbose >= 1:
                                logger = logging.getLogger(__name__)
                                logger.info(f"üìä [–≠–ø–∏–∑–æ–¥ {self.episode_count}] –°—Ä–µ–¥–Ω–µ–µ: {recent_avg:.4f}, –õ—É—á—à–µ–µ: {self.best_reward:.4f}, –ë–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è: {self.episodes_without_improvement}")
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –ø–æ —à–∞–≥–∞–º
        if self.step_count % self.progress_interval == 0 and self.verbose >= 1:
            logger = logging.getLogger(__name__)
            logger.info(f"‚è±Ô∏è [{self.step_count:,} —à–∞–≥–æ–≤] –≠–ø–∏–∑–æ–¥–æ–≤: {self.episode_count}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        if (MLConfig.ENABLE_EARLY_STOPPING and 
            self.episode_count >= self.min_episodes and
            self.episodes_without_improvement >= self.patience):
            
            logger = logging.getLogger(__name__)
            logger.info(f"\nüõë –†–ê–ù–ù–Ø–Ø –û–°–¢–ê–ù–û–í–ö–ê!")
            logger.info(f"   –≠–ø–∏–∑–æ–¥–æ–≤ –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è: {self.episodes_without_improvement}")
            logger.info(f"   –õ—É—á—à–∞—è —Å—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {self.best_reward:.4f}")
            logger.info(f"   –í—Å–µ–≥–æ —ç–ø–∏–∑–æ–¥–æ–≤: {self.episode_count}")
            logger.info(f"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {self.step_count:,}")
            return False  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        
        return True  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ


def create_improved_model(env, device: str = "cpu") -> PPO:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –£–õ–£–ß–®–ï–ù–ù–û–ô –º–æ–¥–µ–ª–∏ PPO —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    
    –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞:
    1. –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    2. –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    3. –õ—É—á—à–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    """
    logger = logging.getLogger(__name__)
    
    logger.info(f"üéØ –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π PPO –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}")
    logger.info(f"üìö –ù–∞—Å—Ç—Ä–æ–π–∫–∏: lr={MLConfig.LEARNING_RATE}, steps={MLConfig.TOTAL_TIMESTEPS:,}")
    
    # –£–õ–£–ß–®–ï–ù–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª–∏—Ç–∏–∫–∏
    policy_kwargs = {
        "features_extractor_class": ImprovedLSTMFeatureExtractor,
        "features_extractor_kwargs": {"features_dim": MLConfig.LSTM_HIDDEN_SIZE},
        # –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏
        "net_arch": [dict(pi=[256, 128], vf=[256, 128])],  # –£–º–µ–Ω—å—à–µ–Ω–æ –æ—Ç [512, 256]
        "activation_fn": nn.ReLU,
        "normalize_images": False
    }
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ê–ì–†–ï–°–°–ò–í–ù–´–ú–ò –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    model = PPO(
        "MlpPolicy",
        env,
        policy_kwargs=policy_kwargs,
        learning_rate=MLConfig.LEARNING_RATE,    # 5e-4 - —É–≤–µ–ª–∏—á–µ–Ω–æ
        n_steps=8192,                            # –£–í–ï–õ–ò–ß–ï–ù–û —Å 4096 –¥–æ 8192
        batch_size=256,                          # –£–í–ï–õ–ò–ß–ï–ù–û —Å 128 –¥–æ 256  
        n_epochs=8,                              # –£–í–ï–õ–ò–ß–ï–ù–û —Å 6 –¥–æ 8
        gamma=0.99,                              # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        gae_lambda=0.95,                         # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        clip_range=0.3,                          # –£–í–ï–õ–ò–ß–ï–ù–û —Å 0.2 –¥–æ 0.3 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        clip_range_vf=None,
        ent_coef=MLConfig.PPO_ENT_COEF,         # 0.1 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ!
        vf_coef=0.25,                           # –£–ú–ï–ù–¨–®–ï–ù–û —Å 0.5 –¥–æ 0.25
        max_grad_norm=1.0,                      # –£–í–ï–õ–ò–ß–ï–ù–û —Å 0.5 –¥–æ 1.0
        device=device,
        verbose=1,
        seed=42                                 # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    )
    
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏")
    return model


def train_improved_model(model: PPO, callback: Optional[SmartEarlyStoppingCallback] = None) -> PPO:
    """
    –û–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º
    """
    logger = logging.getLogger(__name__)
    
    if callback is None:
        callback = SmartEarlyStoppingCallback()
    
    logger.info(f"üöÄ –ù–ê–ß–ê–õ–û –£–õ–£–ß–®–ï–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
    logger.info(f"üéØ –¶–µ–ª—å: {MLConfig.TOTAL_TIMESTEPS:,} —à–∞–≥–æ–≤")
    logger.info(f"üß† –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞: {'–í–∫–ª—é—á–µ–Ω–∞' if MLConfig.ENABLE_EARLY_STOPPING else '–û—Ç–∫–ª—é—á–µ–Ω–∞'}")
    
    try:
        model.learn(
            total_timesteps=MLConfig.TOTAL_TIMESTEPS,
            callback=callback,
            progress_bar=False  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        )
        logger.info("üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        
    except KeyboardInterrupt:
        logger.warning("‚ö†Ô∏è –û–ë–£–ß–ï–ù–ò–ï –ü–†–ï–†–í–ê–ù–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú!")
    except Exception as e:
        logger.error(f"‚ùå –û–®–ò–ë–ö–ê –û–ë–£–ß–ï–ù–ò–Ø: {e}")
        raise
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if hasattr(callback, 'episode_count'):
        logger.info(f"\nüìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"   –≠–ø–∏–∑–æ–¥–æ–≤: {callback.episode_count}")
        logger.info(f"   –®–∞–≥–æ–≤: {callback.step_count:,}")
        logger.info(f"   –õ—É—á—à–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {callback.best_reward:.4f}")
    
    return model


def setup_device() -> str:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π"""
    logger = logging.getLogger(__name__)
    
    if SystemConfig.FORCE_CPU:
        device = "cpu"
        logger.info("üîß –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    elif SystemConfig.AUTO_DEVICE:
        if torch.cuda.is_available():
            device = "cuda"
            try:
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                logger.info(f"üöÄ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω: {gpu_name} ({gpu_memory:.1f} GB)")
            except:
                logger.info("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU")
        else:
            device = "cpu"
            logger.warning("‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    else:
        device = SystemConfig.DEVICE
        logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–¥–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    return device 