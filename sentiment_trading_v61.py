import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from stable_baselines3 import PPO
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.vec_env import DummyVecEnv
import gymnasium as gym
from gymnasium import spaces
import matplotlib.pyplot as plt
from typing import Dict, Tuple, Any
import warnings

warnings.filterwarnings('ignore')

"""
üöÄ –¢–û–†–ì–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê V6.2 - –õ–û–ì–ò–ö–ê –ò–°–ü–†–ê–í–õ–ï–ù–ê
‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ê –ö–õ–Æ–ß–ï–í–ê–Ø –û–®–ò–ë–ö–ê –õ–û–ì–ò–ö–ò: –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–æ –¥–æ 3 (Hold, Buy, Sell).
   - –ê–≥–µ–Ω—Ç —Ç–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è: –æ—Ç–∫—Ä—ã—Ç—å –ø–æ–∑–∏—Ü–∏—é, –∑–∞–∫—Ä—ã—Ç—å –µ–µ –∏–ª–∏ —É–¥–µ—Ä–∂–∏–≤–∞—Ç—å.
   - –£—Å—Ç—Ä–∞–Ω–µ–Ω "—Ü–∏–∫–ª —Å–º–µ—Ä—Ç–∏" (–æ—Ç–∫—Ä—ã—Ç–∏–µ-–∑–∞–∫—Ä—ã—Ç–∏–µ –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏—Ö —à–∞–≥–∞—Ö), –∫–æ—Ç–æ—Ä—ã–π —Å–∂–∏–≥–∞–ª –±–∞–ª–∞–Ω—Å.
‚úÖ –£–ª—É—á—à–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ —à—Ç—Ä–∞—Ñ–∞ –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ (ACTION_COST), —Ç–µ–ø–µ—Ä—å –æ–Ω –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∏ –Ω–∞ –æ—Ç–∫—Ä—ã—Ç–∏–µ, –∏ –Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏–µ.
‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–∞—è CNN –∏ —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è "–¢–µ—Ä–ø–µ–ª–∏–≤–æ–≥–æ –û—Ö–æ—Ç–Ω–∏–∫–∞".
‚úÖ –¶–µ–ª—å: –ü–æ–ª—É—á–∏—Ç—å –ø–µ—Ä–≤—É—é –ª–æ–≥–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –∏ –æ—Ü–µ–Ω–∏—Ç—å –µ–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –æ–±—É—á–µ–Ω–∏—é.
"""

# –í—Ä–∞–ø–ø–µ—Ä, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –¥–ª—è CnnPolicy
class ChannelFirstWrapper(gym.ObservationWrapper):
    def __init__(self, env):
        super().__init__(env)
        old_shape = env.observation_space.shape
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1, old_shape[0], old_shape[1]), dtype=np.float32)

    def observation(self, observation):
        return np.expand_dims(observation, axis=0)
        
# ----------------- –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–ê–®–ê –°–û–ë–°–¢–í–ï–ù–ù–ê–Ø CNN -----------------
class CustomCNN(BaseFeaturesExtractor):
    """
    –ö–∞—Å—Ç–æ–º–Ω–∞—è —Å–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö (64, 7).
    """
    def __init__(self, observation_space: spaces.Box, features_dim: int = 128):
        super().__init__(observation_space, features_dim)
        # observation_space.shape = (1, 64, 7) (–∫–∞–Ω–∞–ª—ã, –≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
        n_input_channels = observation_space.shape[0]
        self.cnn = nn.Sequential(
            # –Ø–¥—Ä–∞ (kernels) –º–µ–Ω—å—à–µ, —á–µ–º —à–∏—Ä–∏–Ω–∞ –Ω–∞—à–µ–≥–æ "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" (7)
            nn.Conv2d(n_input_channels, 32, kernel_size=(3, 3), stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Flatten(),
        )

        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ–∫, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π
        with torch.no_grad():
            # –î–æ–±–∞–≤–ª—è–µ–º .float() –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ç–∏–ø–æ–≤
            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]

        self.linear = nn.Sequential(
            nn.Linear(n_flatten, features_dim),
            nn.ReLU()
        )

    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        return self.linear(self.cnn(observations))

# --------------------------------------------------------------------------

class TrendTraderConfig:
    INITIAL_BALANCE = 10000
    ORDER_SIZE_RATIO = 0.15
    ATR_SL_MULTIPLIER = 2.0
    ATR_TP_MULTIPLIER = 6.0
    TRANSACTION_FEE = 0.001
    ACTION_COST = 0.1  # –°–Ω–∏–∑–∏–ª —Å—Ç–æ–∏–º–æ—Å—Ç—å, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ —Ç–µ–ø–µ—Ä—å –±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º–∞
    WINDOW_SIZE = 64
    TOTAL_TIMESTEPS = 1000000
    LEARNING_RATE = 3e-4
    ENTROPY_COEF = 0.01
    GAMMA = 0.999
    TREND_PROFIT_BONUS = 0.1

class SimpleDataLoader:
    def __init__(self, data_path: str):
        self.data_path = data_path

    def load_and_prepare_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {self.data_path}...")
        df = pd.read_csv(self.data_path)
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['ema_fast'] = df['close'].ewm(span=12, adjust=False).mean()
        df['ema_slow'] = df['close'].ewm(span=26, adjust=False).mean()
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['macd'] = df['ema_fast'] - df['ema_slow']
        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
        df['sma_long'] = df['close'].rolling(window=200).mean()
        
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        df['atr_value'] = tr.ewm(span=14, adjust=False).mean()
        df['rsi_delta'] = df['rsi'].diff(5)
        
        df.dropna(inplace=True)
        df.reset_index(drop=True, inplace=True)
        
        features = pd.DataFrame(index=df.index)
        features['price_norm'] = df['close'] / df['sma_long']
        features['ema_spread'] = (df['ema_fast'] - df['ema_slow']) / df['close']
        features['rsi_norm'] = (df['rsi'] - 50) / 50
        features['macd_hist_norm'] = (df['macd'] - df['macd_signal']) / df['close']
        features['trend_signal'] = np.sign(df['close'] - df['sma_long'])
        features['atr_norm'] = df['atr_value'] / df['close']
        features['rsi_delta_norm'] = features['rsi_norm'].diff(5)
        
        features.replace([np.inf, -np.inf], 0, inplace=True)
        features.dropna(inplace=True)
        prices_df = df.loc[features.index].reset_index(drop=True)
        features.reset_index(drop=True, inplace=True)
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(features)} –∑–∞–ø–∏—Å–µ–π, {len(features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")
        return features, prices_df[['timestamp', 'open', 'high', 'low', 'close', 'atr_value']]

class TradingEnv(gym.Env):
    metadata = {'render_modes': ['human']}
    def __init__(self, features_df: pd.DataFrame, prices_df: pd.DataFrame):
        super().__init__()
        self.features_df = features_df.reset_index(drop=True)
        self.prices_df = prices_df.reset_index(drop=True)
        self.cfg = TrendTraderConfig()
        
        ### –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π ###
        # 0: Hold, 1: Buy, 2: Sell
        self.action_space = spaces.Discrete(3)
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, 
            shape=(self.cfg.WINDOW_SIZE, self.features_df.shape[1]), 
            dtype=np.float32
        )
        self._reset_state()
    
    def _reset_state(self):
        self.balance = self.cfg.INITIAL_BALANCE
        self.equity = self.cfg.INITIAL_BALANCE
        self.current_step = self.cfg.WINDOW_SIZE
        self.position_amount = 0.0
        self.entry_price = 0.0
        self.trades = []
        self.entry_step = 0
        self.stop_loss_price = 0.0
        self.take_profit_price = 0.0
    
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self._reset_state()
        return self._get_observation(), {}
    
    def _get_observation(self):
        start = self.current_step - self.cfg.WINDOW_SIZE
        return self.features_df.iloc[start:self.current_step].values.astype(np.float32)

    def _get_current_price(self) -> float:
        return self.prices_df.iloc[self.current_step]['close']

    def _get_current_atr(self) -> float:
        return self.prices_df.iloc[self.current_step]['atr_value']

    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict[str, Any]]:
        current_price = self._get_current_price()
        reward = 0.0
        done = False

        ### –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π ###
        # –î–µ–π—Å—Ç–≤–∏–µ 1: –ö—É–ø–∏—Ç—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –æ—Ç–∫—Ä—ã—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏)
        if action == 1 and self.position_amount == 0:
            self._open_position(current_price)
            self.balance -= self.cfg.ACTION_COST # –®—Ç—Ä–∞—Ñ –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ
        # –î–µ–π—Å—Ç–≤–∏–µ 2: –ü—Ä–æ–¥–∞—Ç—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–æ–∑–∏—Ü–∏—è)
        elif action == 2 and self.position_amount > 0:
            reward = self._close_position(current_price)
            self.balance -= self.cfg.ACTION_COST # –®—Ç—Ä–∞—Ñ –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ
        # –î–µ–π—Å—Ç–≤–∏–µ 0 (Hold) –∏–ª–∏ –Ω–µ–ª–æ–≥–∏—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (–∫—É–ø–∏—Ç—å –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏, –ø—Ä–æ–¥–∞—Ç—å –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏)
        # –Ω–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é –ø–æ–∑–∏—Ü–∏–∏, –Ω–æ –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –∑–∞–∫—Ä—ã—Ç–∏—é –ø–æ SL/TP.

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ SL/TP –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ, –µ—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è –æ—Ç–∫—Ä—ã—Ç–∞
        if self.position_amount > 0:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –ª–∏ SL –∏–ª–∏ TP –Ω–∞ —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–µ
            low_price = self.prices_df.iloc[self.current_step]['low']
            high_price = self.prices_df.iloc[self.current_step]['high']
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–æ–ø-–ª–æ—Å—Å
            if low_price <= self.stop_loss_price:
                reward = self._close_position(self.stop_loss_price) # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ —Ü–µ–Ω–µ SL
            # –ó–∞—Ç–µ–º —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç
            elif high_price >= self.take_profit_price:
                reward = self._close_position(self.take_profit_price) # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ —Ü–µ–Ω–µ TP

        # –û–±–Ω–æ–≤–ª—è–µ–º —à–∞–≥ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—á–µ—Ç–∞
        self.current_step += 1
        current_unrealized_pnl = (current_price - self.entry_price) * self.position_amount if self.position_amount > 0 else 0
        self.equity = self.balance + current_unrealized_pnl
        
        # –£—Å–ª–æ–≤–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —ç–ø–∏–∑–æ–¥–∞
        if self.current_step >= len(self.features_df) - 1 or self.equity <= 0:
            if self.position_amount > 0:
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à—É—é—Å—è –ø–æ–∑–∏—Ü–∏—é –ø–æ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω–µ, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å
                reward = self._close_position(current_price)
            done = True
        
        # info_dict –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤ gymnasium
        info = {'equity': self.equity}
        # gymnasium –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 5 –∑–Ω–∞—á–µ–Ω–∏–π: obs, reward, terminated, truncated, info
        terminated = done 
        truncated = False # –ú—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–µ—á–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏, done –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ
        
        return self._get_observation(), reward, terminated, truncated, info

    def _open_position(self, price: float):
        self.entry_step = self.current_step
        current_atr = self._get_current_atr()
        
        self.stop_loss_price = price - (current_atr * self.cfg.ATR_SL_MULTIPLIER)
        self.take_profit_price = price + (current_atr * self.cfg.ATR_TP_MULTIPLIER)

        order_size_usd = self.balance * self.cfg.ORDER_SIZE_RATIO
        if self.balance > 0 and order_size_usd > 0:
            fee = order_size_usd * self.cfg.TRANSACTION_FEE
            self.balance -= (order_size_usd + fee)
            self.position_amount = order_size_usd / price
            self.entry_price = price

    def _close_position(self, price: float) -> float:
        close_value = self.position_amount * price
        fee = close_value * self.cfg.TRANSACTION_FEE
        self.balance += (close_value - fee)
        
        # –†–∞—Å—á–µ—Ç PnL —Ç–µ–ø–µ—Ä—å –ø—Ä–æ—â–µ, —Ç.–∫. –±–∞–ª–∞–Ω—Å —É–∂–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–æ–º–∏—Å—Å–∏–∏
        entry_value = self.position_amount * self.entry_price
        realized_pnl = (close_value - fee) - (entry_value + entry_value * self.cfg.TRANSACTION_FEE)
        
        self.trades.append(realized_pnl)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–≥—Ä–∞–¥—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
        reward = realized_pnl / self.cfg.INITIAL_BALANCE
        
        # –ë–æ–Ω—É—Å –∑–∞ —Ç–æ—Ä–≥–æ–≤–ª—é –ø–æ —Ç—Ä–µ–Ω–¥—É
        if realized_pnl > 0:
            trend_at_entry = self.features_df.iloc[self.entry_step]['trend_signal']
            if trend_at_entry > 0: # –ï—Å–ª–∏ –≤—Ö–æ–¥–∏–ª–∏ –≤ –ª–æ–Ω–≥ –ø–æ –±—ã—á—å–µ–º—É —Ç—Ä–µ–Ω–¥—É
                reward += self.cfg.TREND_PROFIT_BONUS
        
        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏
        self.position_amount = 0.0
        self.entry_price = 0.0
        self.stop_loss_price = 0.0
        self.take_profit_price = 0.0
        return reward


def main():
    print("üöÄ –°–ò–°–¢–ï–ú–ê V6.2 (–õ–æ–≥–∏–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞) - –ó–ê–ü–£–°–ö")
    data_loader = SimpleDataLoader("data/BTC_5_96w.csv") # –£–±–µ–¥–∏—Å—å, —á—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Ä–Ω—ã–π
    features_df, prices_df = data_loader.load_and_prepare_data()

    train_split_idx = int(len(features_df) * 0.8)
    train_features, train_prices = features_df.iloc[:train_split_idx], prices_df.iloc[:train_split_idx]
    test_features, test_prices = features_df.iloc[train_split_idx:], prices_df.iloc[train_split_idx:]
    print(f"\n–î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã: {len(train_features)} –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, {len(test_features)} –¥–ª—è —Ç–µ—Å—Ç–∞.")
    
    env_fn = lambda: TradingEnv(train_features, train_prices)
    vec_env = DummyVecEnv([lambda: ChannelFirstWrapper(env_fn())])

    policy_kwargs = dict(
        features_extractor_class=CustomCNN,
        features_extractor_kwargs=dict(features_dim=128),
        net_arch=dict(pi=[128, 64], vf=[128, 64])
    )

    model = PPO('CnnPolicy', vec_env, policy_kwargs=policy_kwargs,
                learning_rate=TrendTraderConfig.LEARNING_RATE, ent_coef=TrendTraderConfig.ENTROPY_COEF,
                n_steps=2048, batch_size=64, gamma=TrendTraderConfig.GAMMA,
                verbose=1, device="cpu") # –ò—Å–ø–æ–ª—å–∑—É–π "cuda", –µ—Å–ª–∏ –µ—Å—Ç—å GPU
    
    print("\nüéì –≠–¢–ê–ü 4: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò...")
    model.learn(total_timesteps=TrendTraderConfig.TOTAL_TIMESTEPS)
    
    print("\nüí∞ –≠–¢–ê–ü 5: –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –ù–ï–í–ò–î–ò–ú–´–• –î–ê–ù–ù–´–•...")
    test_env_raw = TradingEnv(test_features, test_prices)
    test_env_wrapped = ChannelFirstWrapper(test_env_raw)
    
    # ### –ò–ó–ú–ï–ù–ï–ù–ò–ï 3: –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –Ω–æ–≤—ã–º API Gymnasium ###
    obs, info = test_env_wrapped.reset()
    
    equity_history = [test_env_raw.equity]
    price_history = [test_env_raw._get_current_price()]
    
    done = False
    while not done:
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = test_env_wrapped.step(int(action))
        
        equity_history.append(info['equity']) # –ë–µ—Ä–µ–º equity –∏–∑ info dict
        price_history.append(test_env_raw._get_current_price())
        
        done = terminated or truncated
            
    print("\nüìä –≠–¢–ê–ü 6: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    initial_equity, final_equity = equity_history[0], equity_history[-1]
    total_return = (final_equity - initial_equity) / initial_equity * 100
    start_price, end_price = price_history[0], price_history[-1]
    bnh_return = (end_price - start_price) / start_price * 100
    
    total_trades = len(test_env_raw.trades)
    win_rate = (len([t for t in test_env_raw.trades if t > 0]) / total_trades) * 100 if total_trades > 0 else 0

    print("=" * 60)
    print(f"üí∞ –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: ${final_equity:,.2f} (–ù–∞—á–∞–ª—å–Ω—ã–π: ${initial_equity:,.2f})")
    print(f"üìà –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {total_return:+.2f}%")
    print(f"üìä –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å Buy & Hold: {bnh_return:+.2f}%")
    print("-" * 30)
    print(f"üîÑ –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total_trades}")
    print(f"‚úÖ –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫: {win_rate:.1f}%")
    
    plt.style.use('seaborn-v0_8-darkgrid')
    plt.figure(figsize=(15, 7))
    plt.title(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ (V6.2 - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞)\nReturn: {total_return:.2f}% | Trades: {total_trades} | Win Rate: {win_rate:.1f}%')
    ax1 = plt.gca()
    ax1.plot(equity_history, label='Equity', color='royalblue', linewidth=2)
    ax1.set_xlabel('–®–∞–≥–∏')
    ax1.set_ylabel('Equity ($)', color='royalblue')
    
    ax2 = ax1.twinx()
    ax2.plot(price_history, label='–¶–µ–Ω–∞ BTC', color='darkorange', alpha=0.6)
    ax2.set_ylabel('–¶–µ–Ω–∞ ($)', color='darkorange')
    
    ax1.legend(loc='upper left')
    ax2.legend(loc='upper right')
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main() 