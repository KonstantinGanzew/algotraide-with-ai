import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from stable_baselines3 import PPO
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.vec_env import DummyVecEnv
import gymnasium as gym
from gymnasium import spaces
import matplotlib.pyplot as plt
from typing import Dict, Tuple, Any, List
import warnings
import platform

warnings.filterwarnings('ignore')

# –§—É–Ω–∫—Ü–∏—è setup_gpu_support –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
def setup_gpu_support():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º"""
    system = platform.system().lower()
    
    if system == "windows":
        try:
            import torch_directml
            if torch_directml.is_available():
                device = torch_directml.device()
                print(f"‚úÖ DirectML –Ω–∞–π–¥–µ–Ω - AMD GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞: {device}")
                return device
        except ImportError:
            pass
    
    if torch.cuda.is_available():
        device = torch.device("cuda")
        gpu_name = torch.cuda.get_device_name(0)
        print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è NVIDIA CUDA: {gpu_name}")
        return device
    
    device = torch.device("cpu")
    print(f"üíª –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU: {device}")
    return device

# –§—É–Ω–∫—Ü–∏—è get_gpu_memory_info –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
def get_gpu_memory_info(device):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–º—è—Ç–∏ GPU"""
    if device and device.type == "cuda":
        try:
            total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3
            allocated = torch.cuda.memory_allocated(device) / 1024**3
            print(f"üìä GPU –ø–∞–º—è—Ç—å: {allocated:.1f}GB –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ / {total_memory:.1f}GB –≤—Å–µ–≥–æ")
        except Exception:
            pass

"""
üöÄ –¢–û–†–ì–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê V7.0 - –°–¢–†–ê–¢–ï–ì
‚úÖ –¶–ï–õ–¨: –ö–∞—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫, –∞ –Ω–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ. –£—á–∏–º –∞–≥–µ–Ω—Ç–∞ —Ç–µ—Ä–ø–µ–Ω–∏—é –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏.
‚úÖ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù–ê –°–ò–°–¢–ï–ú–ê –ù–ê–ì–†–ê–î: –£–±—Ä–∞–Ω –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π —à—Ç—Ä–∞—Ñ –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ. –í–≤–µ–¥–µ–Ω—ã —á–µ—Ç–∫–∏–µ –±–æ–Ω—É—Å—ã/—à—Ç—Ä–∞—Ñ—ã
   –∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ –∏ –Ω–µ–±–æ–ª—å—à–æ–π "—à—Ç—Ä–∞—Ñ –∑–∞ –±–µ–∑–¥–µ–π—Å—Ç–≤–∏–µ", —á—Ç–æ–±—ã –º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ —Ö–æ—Ä–æ—à–∏—Ö –≤—Ö–æ–¥–æ–≤.
‚úÖ –†–ê–°–®–ò–†–ï–ù–´ –í–û–ó–ú–û–ñ–ù–û–°–¢–ò: –î–æ–±–∞–≤–ª–µ–Ω–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ–∑–∏—Ü–∏–∏ (—à–æ—Ä—Ç—ã),
   —á—Ç–æ–±—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏ –Ω–∞ –ø–∞–¥–µ–Ω–∏–∏ —Ä—ã–Ω–∫–∞.
‚úÖ –£–õ–£–ß–®–ï–ù–ê –û–°–í–ï–î–û–ú–õ–ï–ù–ù–û–°–¢–¨ –ê–ì–ï–ù–¢–ê: –í –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ
   –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–π —Å–¥–µ–ª–∫–∏.
"""

# CustomCombinedExtractor –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
class CustomCombinedExtractor(BaseFeaturesExtractor):
    def __init__(self, observation_space: spaces.Dict, features_dim: int = 256):
        super().__init__(observation_space, features_dim)
        image_space = observation_space['image']
        state_space = observation_space['state']
        n_input_channels = image_space.shape[0]
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 32, kernel_size=(3, 3), stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Flatten(),
        )
        with torch.no_grad():
            sample_image = torch.as_tensor(image_space.sample()[None]).float()
            n_flatten = self.cnn(sample_image).shape[1]
        combined_features_size = n_flatten + state_space.shape[0]
        self.linear = nn.Sequential(
            nn.Linear(combined_features_size, features_dim),
            nn.ReLU()
        )
    def forward(self, observations: Dict[str, torch.Tensor]) -> torch.Tensor:
        image_obs = observations['image']
        state_obs = observations['state']
        cnn_output = self.cnn(image_obs)
        combined_features = torch.cat([cnn_output, state_obs], dim=1)
        return self.linear(combined_features)


class TrendTraderConfig:
    INITIAL_BALANCE = 10000
    TRANSACTION_FEE = 0.001
    WINDOW_SIZE = 64
    
    # ### –ò–ó–ú–ï–ù–ï–ù–ò–ï V7.0: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ "–°—Ç—Ä–∞—Ç–µ–≥–∞" ###
    ORDER_SIZE_RATIO = 0.10  # –°–Ω–∏–∂–∞–µ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∏—Å–∫–∞
    ATR_SL_MULTIPLIER = 3.0  # –ù–µ–º–Ω–æ–≥–æ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å
    ATR_TP_MULTIPLIER = 5.0  # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç (R:R ~ 1:1.67)
    
    # –û–±—É—á–µ–Ω–∏–µ
    TOTAL_TIMESTEPS = 1000000  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    LEARNING_RATE = 3e-4
    ENTROPY_COEF = 0.01
    GAMMA = 0.99
    
    # –ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–≥—Ä–∞–¥
    WIN_BONUS = 0.5         # –ë–æ–ª—å—à–æ–π –±–æ–Ω—É—Å –∑–∞ –ø—Ä–∏–±—ã–ª—å–Ω—É—é —Å–¥–µ–ª–∫—É
    LOSS_PENALTY = -0.5     # –ë–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ —É–±—ã—Ç–æ—á–Ω—É—é —Å–¥–µ–ª–∫—É
    HOLDING_PENALTY = 0.0001 # –ù–µ–±–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ –∫–∞–∂–¥—ã–π —à–∞–≥ –±–µ–∑ –ø–æ–∑–∏—Ü–∏–∏ (—Å—Ç–∏–º—É–ª –∏—Å–∫–∞—Ç—å —Å–¥–µ–ª–∫—É)
    PROFIT_HOLDING_REWARD = 0.01 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –ø–æ–æ—â—Ä–µ–Ω–∏—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø—Ä–∏–±—ã–ª—å–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
    MAX_TRADE_DURATION = 288 # –ú–∞–∫—Å. –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏ –≤ —à–∞–≥–∞—Ö (–¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏). 288*5–º–∏–Ω = 1 —Å—É—Ç–∫–∏

# SimpleDataLoader –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
class SimpleDataLoader:
    def __init__(self, data_path: str):
        self.data_path = data_path
    def load_and_prepare_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {self.data_path}...")
        df = pd.read_csv(self.data_path)
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['ema_fast'] = df['close'].ewm(span=12, adjust=False).mean()
        df['ema_slow'] = df['close'].ewm(span=26, adjust=False).mean()
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['macd'] = df['ema_fast'] - df['ema_slow']
        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
        df['sma_long'] = df['close'].rolling(window=200).mean()
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        df['atr_value'] = tr.ewm(span=14, adjust=False).mean()
        df.dropna(inplace=True)
        df.reset_index(drop=True, inplace=True)
        features = pd.DataFrame(index=df.index)
        features['price_norm'] = df['close'] / df['sma_long']
        features['ema_spread'] = (df['ema_fast'] - df['ema_slow']) / df['close']
        features['rsi_norm'] = (df['rsi'] - 50) / 50
        features['macd_hist_norm'] = (df['macd'] - df['macd_signal']) / df['close']
        features['trend_signal'] = np.sign(df['close'] - df['sma_long'])
        features['atr_norm'] = df['atr_value'] / df['close']
        features.replace([np.inf, -np.inf], 0, inplace=True)
        features.dropna(inplace=True)
        prices_df = df.loc[features.index].reset_index(drop=True)
        features.reset_index(drop=True, inplace=True)
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(features)} –∑–∞–ø–∏—Å–µ–π, {len(features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")
        return features, prices_df[['timestamp', 'open', 'high', 'low', 'close', 'atr_value']]

class TradingEnv(gym.Env):
    metadata = {'render_modes': ['human']}
    def __init__(self, features_df: pd.DataFrame, prices_df: pd.DataFrame):
        super().__init__()
        self.features_df = features_df.reset_index(drop=True)
        self.prices_df = prices_df.reset_index(drop=True)
        self.cfg = TrendTraderConfig()
        
        # ### –ò–ó–ú–ï–ù–ï–ù–ò–ï V7.0: –ù–æ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π —Å —à–æ—Ä—Ç–∞–º–∏ ###
        # 0: Hold, 1: Buy (Long), 2: Sell (Short), 3: Close Position
        self.action_space = spaces.Discrete(4)
        
        # ### –ò–ó–ú–ï–ù–ï–ù–ò–ï V7.0: –ù–æ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π ###
        self.observation_space = spaces.Dict({
            "image": spaces.Box(
                low=-np.inf, high=np.inf, 
                shape=(1, self.cfg.WINDOW_SIZE, self.features_df.shape[1]), 
                dtype=np.float32
            ),
            # –í–µ–∫—Ç–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è: [—Ç–∏–ø –ø–æ–∑–∏—Ü–∏–∏, –Ω–µ—Ä–µ–∞–ª–∏–∑. PnL, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∑–∏—Ü–∏–∏]
            "state": spaces.Box(low=-np.inf, high=np.inf, shape=(3,), dtype=np.float32)
        })
        self._reset_state()
    
    def _reset_state(self):
        self.balance = self.cfg.INITIAL_BALANCE
        self.equity = self.cfg.INITIAL_BALANCE
        self.current_step = self.cfg.WINDOW_SIZE
        self.position_amount = 0.0 # >0 –¥–ª—è Long, <0 –¥–ª—è Short
        self.entry_price = 0.0
        self.entry_step = 0
        self.stop_loss_price = 0.0
        self.take_profit_price = 0.0
        self.trades = []

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self._reset_state()
        return self._get_observation(), {}
    
    def _get_observation(self) -> Dict[str, np.ndarray]:
        market_obs = self.features_df.iloc[self.current_step - self.cfg.WINDOW_SIZE : self.current_step].values
        image_obs = np.expand_dims(market_obs, axis=0).astype(np.float32)

        position_type = np.sign(self.position_amount) # 1.0 –¥–ª—è Long, -1.0 –¥–ª—è Short, 0.0 –¥–ª—è Flat
        
        if self.position_amount != 0:
            current_price = self._get_current_price()
            pnl = (current_price - self.entry_price) * self.position_amount
            unrealized_pnl_norm = pnl / (self.entry_price * abs(self.position_amount))
            duration_norm = (self.current_step - self.entry_step) / self.cfg.MAX_TRADE_DURATION
        else:
            unrealized_pnl_norm = 0.0
            duration_norm = 0.0
            
        state_obs = np.array([position_type, unrealized_pnl_norm, duration_norm], dtype=np.float32)

        return {"image": image_obs, "state": state_obs}

    def _get_current_price(self) -> float:
        return self.prices_df.iloc[self.current_step]['close']

    def _get_current_atr(self) -> float:
        return self.prices_df.iloc[self.current_step]['atr_value']

    def step(self, action: int) -> Tuple[Dict[str, np.ndarray], float, bool, bool, Dict[str, Any]]:
        current_price = self._get_current_price()
        reward = 0.0
        done = False

        # ### –ò–ó–ú–ï–ù–ï–ù–ò–ï V7.0: –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –Ω–∞–≥—Ä–∞–¥ ###
        # --- –õ–æ–≥–∏–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π ---
        if self.position_amount == 0: # –ï—Å–ª–∏ –º—ã –≤–Ω–µ –ø–æ–∑–∏—Ü–∏–∏
            if action == 1: # –û—Ç–∫—Ä—ã—Ç—å Long
                self._open_position(current_price, is_long=True)
            elif action == 2: # –û—Ç–∫—Ä—ã—Ç—å Short
                self._open_position(current_price, is_long=False)
            else: # –î–µ—Ä–∂–∞—Ç—å (Hold)
                reward -= self.cfg.HOLDING_PENALTY # –ù–∞–∫–∞–∑—ã–≤–∞–µ–º –∑–∞ –±–µ–∑–¥–µ–π—Å—Ç–≤–∏–µ
        
        elif self.position_amount != 0: # –ï—Å–ª–∏ –º—ã –≤ –ø–æ–∑–∏—Ü–∏–∏
            if action == 3: # –ó–∞–∫—Ä—ã—Ç—å —Ç–µ–∫—É—â—É—é –ø–æ–∑–∏—Ü–∏—é
                reward = self._close_position(current_price)
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏—è "Buy" –∏–ª–∏ "Sell", –µ—Å–ª–∏ —É–∂–µ –≤ –ø–æ–∑–∏—Ü–∏–∏
        
        # --- –õ–æ–≥–∏–∫–∞ SL/TP –∏ –Ω–∞–≥—Ä–∞–¥ –∑–∞ —É–¥–µ—Ä–∂–∞–Ω–∏–µ ---
        if self.position_amount != 0:
            low_price = self.prices_df.iloc[self.current_step]['low']
            high_price = self.prices_df.iloc[self.current_step]['high']
            
            is_long = self.position_amount > 0
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ Stop Loss / Take Profit
            if (is_long and low_price <= self.stop_loss_price) or (not is_long and high_price >= self.stop_loss_price):
                reward = self._close_position(self.stop_loss_price)
            elif (is_long and high_price >= self.take_profit_price) or (not is_long and low_price <= self.take_profit_price):
                reward = self._close_position(self.take_profit_price)
            else:
                # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ —É–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–∏–±—ã–ª—å–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
                pnl = (current_price - self.entry_price) * self.position_amount
                if pnl > 0:
                    reward += self.cfg.PROFIT_HOLDING_REWARD

        # --- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —à–∞–≥–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ---
        self.current_step += 1
        current_unrealized_pnl = (self._get_current_price() - self.entry_price) * self.position_amount
        self.equity = self.balance + current_unrealized_pnl
        
        if self.current_step >= len(self.features_df) - 1 or self.equity <= 0:
            if self.position_amount != 0:
                reward = self._close_position(self._get_current_price())
            done = True
        
        info = {'equity': self.equity}
        return self._get_observation(), reward, done, False, info

    def _open_position(self, price: float, is_long: bool):
        self.entry_step = self.current_step
        current_atr = self._get_current_atr()
        
        if is_long:
            self.stop_loss_price = price - (current_atr * self.cfg.ATR_SL_MULTIPLIER)
            self.take_profit_price = price + (current_atr * self.cfg.ATR_TP_MULTIPLIER)
        else: # Short
            self.stop_loss_price = price + (current_atr * self.cfg.ATR_SL_MULTIPLIER)
            self.take_profit_price = price - (current_atr * self.cfg.ATR_TP_MULTIPLIER)

        order_size_usd = self.balance * self.cfg.ORDER_SIZE_RATIO
        if self.balance > 0 and order_size_usd > 0:
            fee = order_size_usd * self.cfg.TRANSACTION_FEE
            self.balance -= (order_size_usd + fee)
            position_size = order_size_usd / price
            self.position_amount = position_size if is_long else -position_size
            self.entry_price = price

    def _close_position(self, price: float) -> float:
        is_long = self.position_amount > 0
        position_size = abs(self.position_amount)
        close_value = position_size * price
        fee = close_value * self.cfg.TRANSACTION_FEE
        
        entry_value = position_size * self.entry_price
        entry_fee = entry_value * self.cfg.TRANSACTION_FEE
        
        if is_long:
            realized_pnl = (close_value - fee) - (entry_value + entry_fee)
        else: # Short
            realized_pnl = (entry_value - entry_fee) - (close_value + fee)

        self.balance += entry_value + realized_pnl # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–ª–æ —Å–¥–µ–ª–∫–∏ –∏ PnL
        self.trades.append(realized_pnl)
        
        # ### –ò–ó–ú–ï–ù–ï–ù–ò–ï V7.0: –ù–∞–≥—Ä–∞–¥–∞ —Å –±–æ–Ω—É—Å–æ–º/—à—Ç—Ä–∞—Ñ–æ–º ###
        reward = 0
        if realized_pnl > 0:
            reward += self.cfg.WIN_BONUS
        else:
            reward += self.cfg.LOSS_PENALTY
            
        self.position_amount = 0.0
        self.entry_price = 0.0
        return reward


def main():
    print("üöÄ –°–ò–°–¢–ï–ú–ê V7.0 (–°—Ç—Ä–∞—Ç–µ–≥) - –ó–ê–ü–£–°–ö")
    device = setup_gpu_support()
    get_gpu_memory_info(device)
    
    data_loader = SimpleDataLoader("data/BTC_5_96w.csv")
    features_df, prices_df = data_loader.load_and_prepare_data()

    train_split_idx = int(len(features_df) * 0.8)
    train_features, train_prices = features_df.iloc[:train_split_idx], prices_df.iloc[:train_split_idx]
    test_features, test_prices = features_df.iloc[train_split_idx:], prices_df.iloc[train_split_idx:]
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã: {len(train_features)} –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, {len(test_features)} –¥–ª—è —Ç–µ—Å—Ç–∞.")
    
    vec_env = DummyVecEnv([lambda: TradingEnv(train_features, train_prices)])

    policy_kwargs = dict(
        features_extractor_class=CustomCombinedExtractor,
        features_extractor_kwargs=dict(features_dim=256),
        net_arch=dict(pi=[256, 128], vf=[256, 128])
    )

    model = PPO('MultiInputPolicy', vec_env, policy_kwargs=policy_kwargs,
                learning_rate=TrendTraderConfig.LEARNING_RATE, ent_coef=TrendTraderConfig.ENTROPY_COEF,
                n_steps=2048, batch_size=64, gamma=TrendTraderConfig.GAMMA,
                verbose=1, device=device)

    print("\nüéì –≠–¢–ê–ü 4: –û–ë–£–ß–ï–ù–ò–ï '–°–¢–†–ê–¢–ï–ì–ê' (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏)...")
    model.learn(total_timesteps=TrendTraderConfig.TOTAL_TIMESTEPS)
    
    print("\nüí∞ –≠–¢–ê–ü 5: –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –ù–ï–í–ò–î–ò–ú–´–• –î–ê–ù–ù–´–•...")
    test_env = TradingEnv(test_features, test_prices)
    obs, info = test_env.reset()
    
    equity_history = [test_env.equity]
    price_history = [test_env._get_current_price()]
    
    done = False
    while not done:
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = test_env.step(int(action))
        equity_history.append(info['equity'])
        try:
            price_history.append(test_env._get_current_price())
        except IndexError:
            price_history.append(price_history[-1])
        done = terminated or truncated
            
    print("\nüìä –≠–¢–ê–ü 6: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í '–°–¢–†–ê–¢–ï–ì–ê'")
    initial_equity, final_equity = equity_history[0], equity_history[-1]
    total_return = (final_equity - initial_equity) / initial_equity * 100
    start_price, end_price = price_history[0], price_history[-1]
    bnh_return = (end_price - start_price) / start_price * 100
    total_trades = len(test_env.trades)
    win_rate = (len([t for t in test_env.trades if t > 0]) / total_trades) * 100 if total_trades > 0 else 0

    print("=" * 60)
    print(f"üí∞ –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: ${final_equity:,.2f} (–ù–∞—á–∞–ª—å–Ω—ã–π: ${initial_equity:,.2f})")
    print(f"üìà –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {total_return:+.2f}%")
    print(f"üìä –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å Buy & Hold: {bnh_return:+.2f}%")
    print("-" * 30)
    print(f"üîÑ –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total_trades}")
    print(f"‚úÖ –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫: {win_rate:.1f}%")
    
    plt.style.use('seaborn-v0_8-darkgrid')
    plt.figure(figsize=(15, 7))
    plt.title(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ (V7.0 - –°—Ç—Ä–∞—Ç–µ–≥)\nReturn: {total_return:.2f}% | Trades: {total_trades} | Win Rate: {win_rate:.1f}%')
    ax1 = plt.gca()
    ax1.plot(equity_history, label='Equity', color='royalblue', linewidth=2)
    ax1.set_xlabel('–®–∞–≥–∏'); ax1.set_ylabel('Equity ($)', color='royalblue');
    ax2 = ax1.twinx()
    ax2.plot(price_history, label='–¶–µ–Ω–∞ BTC', color='darkorange', alpha=0.6)
    ax2.set_ylabel('–¶–µ–Ω–∞ ($)', color='darkorange');
    ax1.legend(loc='upper left'); ax2.legend(loc='upper right')
    plt.tight_layout(); plt.show()


if __name__ == "__main__":
    main()
