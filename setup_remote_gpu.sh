#!/bin/bash

# üöÄ –£–°–¢–ê–ù–û–í–û–ß–ù–´–ô –°–ö–†–ò–ü–¢ –î–õ–Ø –£–î–ê–õ–ï–ù–ù–û–ì–û GPU –°–ï–†–í–ï–†–ê
# –°–µ—Ä–≤–µ—Ä: 192.168.88.218 (NVIDIA GPU + CUDA 12.8)

echo "üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä–µ..."
echo "======================================"

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA GPU
log_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA GPU..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader
    log_success "NVIDIA GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω"
else
    log_error "NVIDIA GPU –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –¥—Ä–∞–π–≤–µ—Ä—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
log_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA..."
if command -v nvcc &> /dev/null; then
    CUDA_VERSION=$(nvcc --version | grep "release" | awk '{print $6}' | cut -c2-)
    log_success "CUDA –≤–µ—Ä—Å–∏—è: $CUDA_VERSION"
else
    log_warning "NVCC –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ PATH, –Ω–æ CUDA –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
fi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Python
log_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ Python..."
if command -v python3 &> /dev/null; then
    PYTHON_VERSION=$(python3 --version)
    log_success "$PYTHON_VERSION"
else
    log_error "Python3 –Ω–µ –Ω–∞–π–¥–µ–Ω"
    exit 1
fi

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
WORK_DIR="$HOME/gpu_training"
log_info "–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: $WORK_DIR"
mkdir -p $WORK_DIR
mkdir -p $WORK_DIR/data
mkdir -p $WORK_DIR/logs
mkdir -p $WORK_DIR/models
mkdir -p $WORK_DIR/results

cd $WORK_DIR

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã
log_info "–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã..."
if [ ! -d "venv" ]; then
    python3 -m venv venv
    log_success "–í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Å—Ä–µ–¥–∞ —Å–æ–∑–¥–∞–Ω–∞"
else
    log_warning "–í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Å—Ä–µ–¥–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
fi

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã
log_info "–ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã..."
source venv/bin/activate

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip
log_info "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip..."
pip install --upgrade pip

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA
log_info "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch CUDA
log_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch CUDA..."
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}'); print(f'GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}')"

if python3 -c "import torch; exit(0 if torch.cuda.is_available() else 1)"; then
    log_success "PyTorch —Å CUDA –Ω–∞—Å—Ç—Ä–æ–µ–Ω —É—Å–ø–µ—à–Ω–æ"
else
    log_error "PyTorch CUDA –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"
    exit 1
fi

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
log_info "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π..."
pip install stable-baselines3>=2.2.1
pip install gymnasium>=0.29.0
pip install numpy pandas scikit-learn
pip install matplotlib seaborn
pip install tqdm psutil scipy
pip install tensorboard wandb
pip install ccxt>=4.0.0
pip install optuna joblib

log_success "–í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU
log_info "–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞..."
cat > test_gpu.py << 'EOF'
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
"""
import torch
import time

print("üéÆ –¢–ï–°–¢ GPU –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
print("=" * 40)

# –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
print(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {torch.cuda.device_count()}")
    
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f"\nGPU {i}: {props.name}")
        print(f"  –ü–∞–º—è—Ç—å: {props.total_memory / 1024**3:.1f} GB")
        print(f"  –ú—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤: {props.multi_processor_count}")
        print(f"  CUDA –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏: {props.major}.{props.minor}")
    
    # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    print("\nüöÄ –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    device = torch.device('cuda:0')
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª—å—à–æ–π –º–∞—Ç—Ä–∏—Ü—ã –Ω–∞ GPU
    size = 5000
    print(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã {size}x{size} –Ω–∞ GPU...")
    
    start_time = time.time()
    a = torch.randn(size, size, device=device)
    b = torch.randn(size, size, device=device)
    
    # –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ
    c = torch.matmul(a, b)
    torch.cuda.synchronize()  # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    
    gpu_time = time.time() - start_time
    print(f"–í—Ä–µ–º—è –Ω–∞ GPU: {gpu_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
    del a, b, c
    torch.cuda.empty_cache()
    
    print("‚úÖ GPU —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
else:
    print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
EOF

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ GPU
log_info "–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ GPU..."
python3 test_gpu.py

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GPU
cat > monitor_gpu.py << 'EOF'
#!/usr/bin/env python3
"""
–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
"""
import subprocess
import time
import os

def get_gpu_info():
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        return result.stdout.strip().split('\n')
    except:
        return None

def monitor_gpu():
    print("üéÆ –ú–û–ù–ò–¢–û–†–ò–ù–ì GPU (Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
    print("=" * 50)
    
    try:
        while True:
            os.system('clear')
            print("üéÆ –ú–û–ù–ò–¢–û–†–ò–ù–ì GPU")
            print("=" * 50)
            
            gpu_info = get_gpu_info()
            if gpu_info:
                for i, info in enumerate(gpu_info):
                    if info.strip():
                        util, mem_used, mem_total, temp = info.split(', ')
                        mem_percent = (int(mem_used) / int(mem_total)) * 100
                        
                        print(f"GPU {i}:")
                        print(f"  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {util}%")
                        print(f"  –ü–∞–º—è—Ç—å: {mem_used}MB / {mem_total}MB ({mem_percent:.1f}%)")
                        print(f"  –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temp}¬∞C")
                        print()
            
            time.sleep(2)
            
    except KeyboardInterrupt:
        print("\nüëã –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

if __name__ == "__main__":
    monitor_gpu()
EOF

log_success "–¢–µ—Å—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã —Å–æ–∑–¥–∞–Ω—ã"

# –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
echo ""
log_success "‚úÖ –ù–ê–°–¢–†–û–ô–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!"
echo "======================================"
echo ""
echo "üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: $WORK_DIR"
echo "üîß –ê–∫—Ç–∏–≤–∞—Ü–∏—è —Å—Ä–µ–¥—ã: source $WORK_DIR/venv/bin/activate"
echo "üß™ –¢–µ—Å—Ç GPU: python3 test_gpu.py"
echo "üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU: python3 monitor_gpu.py"
echo ""
echo "üöÄ –î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è:"
echo "   1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª—ã –æ–±—É—á–µ–Ω–∏—è –≤ $WORK_DIR"
echo "   2. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ —Å—Ä–µ–¥—É: source venv/bin/activate"
echo "   3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python3 sentiment_trading_v69_remote.py"
echo ""

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ
cat > system_info.txt << EOF
GPU Training Environment Setup
==============================
Date: $(date)
Host: $(hostname)
User: $(whoami)
Working Directory: $WORK_DIR

GPU Information:
$(nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv)

CUDA Version:
$(nvcc --version 2>/dev/null || echo "NVCC not in PATH")

Python Version:
$(python3 --version)

PyTorch Version:
$(python3 -c "import torch; print(torch.__version__)" 2>/dev/null || echo "PyTorch not installed")
EOF

log_info "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ system_info.txt"
log_success "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ! üéâ" 